import { jest } from "@jest/globals";
import ClaudeCodeProvider from "../../../src/ai-providers/claude-code.js";
import { vi } from "vitest";

// Mock MCP tools globally
const mockMcpTool = jest.fn();
const mockSequentialThinking = jest.fn();
const mockCodeReasoning = jest.fn();
const mockWebSearch = jest.fn();
const mockPerplexityAsk = jest.fn();

global.mcp__sequential_thinking__sequentialthinking = mockSequentialThinking;
global.mcp__code_reasoning__code_reasoning = mockCodeReasoning;
global.WebSearch = mockWebSearch;
global.mcp__perplexity_ask__perplexity_ask = mockPerplexityAsk;

// Mock console methods
const originalLog = console.log;
const originalError = console.error;

beforeEach(() => {
	console.log = jest.fn();
	console.error = jest.fn();
	jest.clearAllMocks();
});

afterEach(() => {
	console.log = originalLog;
	console.error = originalError;
});

describe("ClaudeCodeProvider", () => {
	let provider;

	beforeEach(() => {
		provider = new ClaudeCodeProvider();
		jest.clearAllMocks();
	});

	describe("Configuration", () => {
		it("should have correct name and capabilities", () => {
			expect(provider.name).toBe("claude-code");
			expect(provider.apiKeyEnvVar).toBe("ANTHROPIC_API_KEY");
			expect(provider.nativeTools).toBe(true);
			expect(provider.supportedTools).toEqual(["research", "thinking"]);
		});

		it("should configure correct models", () => {
			expect(provider.models).toEqual({
				fast: "claude-3-haiku-20240307",
				balanced: "claude-3-5-sonnet-20241022",
				powerful: "claude-3-5-sonnet-20241022",
			});
		});
	});

	describe("generateText", () => {
		it("should use console.log for text generation", async () => {
			const messages = [
				{ role: "system", content: "You are a helpful assistant" },
				{ role: "user", content: "Hello" },
			];

			const result = await provider.generateText("Hello", messages, {
				temperature: 0.7,
			});

			expect(console.log).toHaveBeenCalledWith("[MCP Tool Request]");
			expect(console.log).toHaveBeenCalledWith(
				JSON.stringify({
					type: "text_generation",
					messages,
					options: { temperature: 0.7 },
				}),
			);
			expect(result).toBe("[Claude Code will generate response]");
		});

		it("should handle research tool when modelOverride is research", async () => {
			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Research query" },
			];

			await provider.generateTextWithTools(
				"Research query",
				messages,
				{ modelOverride: "research" },
				["research"],
			);

			expect(mockPerplexityAsk).toHaveBeenCalledWith({
				messages: [{ role: "user", content: "Research query" }],
			});
		});
	});

	describe("generateTextWithTools", () => {
		it("should handle sequential thinking tool", async () => {
			mockSequentialThinking.mockResolvedValue({
				result: "Thinking result",
			});

			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Think about this" },
			];

			const result = await provider.generateTextWithTools(
				"Think about this",
				messages,
				{},
				["thinking"],
			);

			expect(mockSequentialThinking).toHaveBeenCalledWith({
				thought: "Think about this",
				nextThoughtNeeded: true,
				thoughtNumber: 1,
				totalThoughts: 1,
			});
			expect(result).toBe("Thinking result");
		});

		it("should handle code reasoning tool", async () => {
			mockCodeReasoning.mockResolvedValue({
				result: "Code reasoning result",
			});

			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Analyze this code" },
			];

			const result = await provider.generateTextWithTools(
				"Analyze this code",
				messages,
				{},
				["thinking"],
			);

			// Should try sequential thinking first, then fall back to code reasoning
			expect(mockSequentialThinking).toHaveBeenCalled();
			expect(mockCodeReasoning).toHaveBeenCalledWith({
				thought: "Analyze this code",
				thought_number: 1,
				total_thoughts: 1,
				next_thought_needed: true,
			});
			expect(result).toBe("Code reasoning result");
		});

		it("should handle web search tool", async () => {
			mockWebSearch.mockResolvedValue({
				result: "Search results",
			});

			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Search for information" },
			];

			const result = await provider.generateTextWithTools(
				"Search for information",
				messages,
				{},
				["research"],
			);

			expect(mockWebSearch).toHaveBeenCalledWith({
				query: "Search for information",
			});
			expect(result).toBe("Search results");
		});

		it("should handle perplexity tool for research", async () => {
			mockPerplexityAsk.mockResolvedValue({
				result: "Perplexity response",
			});

			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Research this topic" },
			];

			const result = await provider.generateTextWithTools(
				"Research this topic",
				messages,
				{ modelOverride: "research" },
				["research"],
			);

			expect(mockPerplexityAsk).toHaveBeenCalledWith({
				messages: [{ role: "user", content: "Research this topic" }],
			});
			expect(result).toBe("Perplexity response");
		});

		it("should fallback to regular text generation when no tools match", async () => {
			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Regular prompt" },
			];

			const result = await provider.generateTextWithTools(
				"Regular prompt",
				messages,
				{},
				["unknown-tool"],
			);

			expect(console.log).toHaveBeenCalledWith("[MCP Tool Request]");
			expect(result).toBe("[Claude Code will generate response]");
		});

		it("should handle tool errors gracefully", async () => {
			mockSequentialThinking.mockRejectedValue(new Error("Tool error"));

			const messages = [
				{ role: "system", content: "System prompt" },
				{ role: "user", content: "Think about this" },
			];

			const result = await provider.generateTextWithTools(
				"Think about this",
				messages,
				{},
				["thinking"],
			);

			expect(console.error).toHaveBeenCalledWith(
				"[Claude Code] Tool error:",
				expect.any(Error),
			);
			expect(result).toBe("[Claude Code will generate response]");
		});
	});

	describe("countTokens", () => {
		it("should estimate tokens for messages", () => {
			const messages = [
				{ role: "system", content: "You are helpful" },
				{ role: "user", content: "Hello world" },
				{ role: "assistant", content: "Hi there!" },
			];

			const count = provider.countTokens(messages);
			// Rough estimate: ~4 chars per token
			expect(count).toBeGreaterThan(0);
			expect(count).toBeLessThan(100);
		});

		it("should handle empty messages", () => {
			expect(provider.countTokens([])).toBe(0);
		});

		it("should handle messages without content", () => {
			const messages = [
				{ role: "user" },
				{ role: "assistant", content: null },
			];
			const count = provider.countTokens(messages);
			expect(count).toBe(0);
		});
	});

	describe("Model selection", () => {
		it("should select correct model tier", () => {
			// Direct access to selectModel via instance
			expect(provider.selectModel("fast")).toBe("claude-3-haiku-20240307");
			expect(provider.selectModel("balanced")).toBe(
				"claude-3-5-sonnet-20241022",
			);
			expect(provider.selectModel("powerful")).toBe(
				"claude-3-5-sonnet-20241022",
			);
		});

		it("should handle model override", () => {
			const model = provider.selectModel("fast", "claude-3-opus-20240229");
			expect(model).toBe("claude-3-opus-20240229");
		});

		it("should default to balanced model", () => {
			expect(provider.selectModel()).toBe("claude-3-5-sonnet-20241022");
			expect(provider.selectModel("unknown")).toBe(
				"claude-3-5-sonnet-20241022",
			);
		});
	});

	describe("Tool detection", () => {
		it("should detect thinking tools from content", () => {
			const thinkingPrompts = [
				"think step by step about this",
				"analyze this problem sequentially",
				"reason through this code",
				"let's think about this",
			];

			thinkingPrompts.forEach((prompt) => {
				const result = provider.generateTextWithTools(
					prompt,
					[{ role: "user", content: prompt }],
					{},
					["thinking"],
				);
				// Just verify the method runs without error
				expect(result).toBeDefined();
			});
		});

		it("should detect research tools from content", () => {
			const researchPrompts = [
				"search for information about",
				"research this topic",
				"find current information on",
				"look up recent data about",
			];

			researchPrompts.forEach((prompt) => {
				const result = provider.generateTextWithTools(
					prompt,
					[{ role: "user", content: prompt }],
					{},
					["research"],
				);
				// Just verify the method runs without error
				expect(result).toBeDefined();
			});
		});
	});

	describe("extractUsageFromMessages", () => {
		it("should extract usage statistics from message history", () => {
			const messages = [
				{ role: "user", content: "Hello" },
				{
					role: "assistant",
					content: "Hi there!",
					usage: {
						prompt_tokens: 10,
						completion_tokens: 5,
						total_tokens: 15,
					},
				},
				{ role: "user", content: "How are you?" },
				{
					role: "assistant",
					content: "I'm doing well!",
					usage: {
						prompt_tokens: 20,
						completion_tokens: 8,
						total_tokens: 28,
					},
				},
			];

			const usage = provider.extractUsageFromMessages(messages);
			expect(usage).toEqual({
				prompt_tokens: 30,
				completion_tokens: 13,
				total_tokens: 43,
			});
		});

		it("should handle messages without usage data", () => {
			const messages = [
				{ role: "user", content: "Hello" },
				{ role: "assistant", content: "Hi!" },
			];

			const usage = provider.extractUsageFromMessages(messages);
			expect(usage).toEqual({
				prompt_tokens: 0,
				completion_tokens: 0,
				total_tokens: 0,
			});
		});

		it("should handle empty messages array", () => {
			const usage = provider.extractUsageFromMessages([]);
			expect(usage).toEqual({
				prompt_tokens: 0,
				completion_tokens: 0,
				total_tokens: 0,
			});
		});

		it("should handle partial usage data", () => {
			const messages = [
				{
					role: "assistant",
					content: "Response",
					usage: { prompt_tokens: 10 },
				},
				{
					role: "assistant",
					content: "Another",
					usage: { completion_tokens: 5 },
				},
			];

			const usage = provider.extractUsageFromMessages(messages);
			expect(usage).toEqual({
				prompt_tokens: 10,
				completion_tokens: 5,
				total_tokens: 15,
			});
		});
	});

	describe("getCapabilities", () => {
		it("should return comprehensive provider capabilities", () => {
			const capabilities = provider.getCapabilities();

			expect(capabilities).toEqual({
				streaming: false,
				functions: false,
				vision: true,
				contextWindow: 200000,
				maxOutputTokens: 8192,
				supportedTools: ["research", "thinking"],
				nativeTools: true,
			});
		});
	});

	describe("AbortController support", () => {
		it("should pass abortSignal to tool calls", async () => {
			const abortController = new AbortController();
			const messages = [{ role: "user", content: "Think about this" }];

			mockSequentialThinking.mockImplementation(async (params) => {
				// Simulate checking abort signal
				if (abortController.signal.aborted) {
					throw new Error("Aborted");
				}
				return { result: "Completed" };
			});

			const resultPromise = provider.generateTextWithTools(
				"Think about this",
				messages,
				{ abortSignal: abortController.signal },
				["thinking"],
			);

			// Don't abort, should complete normally
			const result = await resultPromise;
			expect(result).toBe("Completed");
		});

		it("should handle aborted requests", async () => {
			const abortController = new AbortController();
			const messages = [{ role: "user", content: "Think about this" }];

			mockSequentialThinking.mockImplementation(async () => {
				// Simulate some async work
				await new Promise((resolve) => setTimeout(resolve, 10));
				throw new Error("The operation was aborted");
			});

			// Abort immediately
			abortController.abort();

			const result = await provider.generateTextWithTools(
				"Think about this",
				messages,
				{ abortSignal: abortController.signal },
				["thinking"],
			);

			expect(console.error).toHaveBeenCalledWith(
				"[Claude Code] Tool error:",
				expect.any(Error),
			);
			expect(result).toBe("[Claude Code will generate response]");
		});
	});

	describe("Model parameters", () => {
		it("should pass temperature to tools", async () => {
			const messages = [{ role: "user", content: "Think creatively" }];

			await provider.generateTextWithTools(
				"Think creatively",
				messages,
				{ temperature: 0.9 },
				["thinking"],
			);

			// Temperature is not directly passed to thinking tools,
			// but the option should be accepted without error
			expect(mockSequentialThinking).toHaveBeenCalled();
		});

		it("should handle max_tokens parameter", async () => {
			const messages = [{ role: "user", content: "Generate text" }];

			const result = await provider.generateText("Generate text", messages, {
				max_tokens: 1000,
			});

			expect(console.log).toHaveBeenCalledWith(
				expect.stringContaining('"max_tokens":1000'),
			);
		});
	});
});